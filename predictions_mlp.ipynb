{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from copy import copy\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scaler import FeaturesScaler\n",
    "from dataloader import SimpleMagni\n",
    "from simple_mlp import LightPointPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRAS_PATH = \"lhmp-thor-magni-challenge-extras\"  # set path to package directory\n",
    "DATA_PATH = os.path.join(EXTRAS_PATH, \"data\")  # path to data directory\n",
    "SCENARIOS = [\"Scenario_1\", \"Scenario_2\", \"Scenario_3\", \"Scenario_4\", \"Scenario_5\"]\n",
    "\n",
    "CHECKPOINTS_PATHS = {\n",
    "    \"Scenario_1\": f\"{EXTRAS_PATH}/logs/Scenario_1_simple_mlp/version_0/checkpoints/epoch=35-val_loss=0.85.ckpt\",\n",
    "    \"Scenario_2\": f\"{EXTRAS_PATH}/logs/Scenario_2_simple_mlp/version_0/checkpoints/epoch=45-val_loss=0.87.ckpt\",\n",
    "    \"Scenario_3\": f\"{EXTRAS_PATH}/logs/Scenario_3_simple_mlp/version_0/checkpoints/epoch=37-val_loss=0.89.ckpt\",\n",
    "    \"Scenario_4\": f\"{EXTRAS_PATH}/logs/Scenario_4_simple_mlp/version_0/checkpoints/epoch=19-val_loss=0.81.ckpt\",\n",
    "    \"Scenario_5\": f\"{EXTRAS_PATH}/logs/Scenario_5_simple_mlp/version_0/checkpoints/epoch=29-val_loss=0.66.ckpt\",\n",
    "}  # set path to checkpoints\n",
    "\n",
    "HYPERPARAMETERS = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"bs\": 32,\n",
    "    \"scheduler_patience\": 5,\n",
    "    \"val_freq\": 2,  # validation every n epochs\n",
    "    \"patience\": 10,  # 10 epochs early stopping\n",
    "}\n",
    "DATA_CONFIG = {\n",
    "    \"inputs\": [\"speeds\"],\n",
    "    \"obs_len\": 8,\n",
    "    \"pred_len\": 12,\n",
    "    \"output\": \"speeds\",\n",
    "}\n",
    "NETWORK_CONFIG = {\n",
    "    \"hidden_units\": [32, 16],\n",
    "    \"dropout\": 0.2,\n",
    "    \"batch_norm\": True,\n",
    "    \"activation\": \"prelu\",\n",
    "    \"obs_len\": DATA_CONFIG[\"obs_len\"],\n",
    "    \"pred_len\": 12,\n",
    "    \"n_features\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dl_and_stats(test_scenario: str):\n",
    "    train_scenarios = copy(SCENARIOS)\n",
    "    train_scenarios.remove(test_scenario)\n",
    "    train_tracklets = []\n",
    "    for train_scenario in train_scenarios:\n",
    "        df = pd.read_csv(\n",
    "            os.path.join(DATA_PATH, train_scenario + \".csv\"), index_col=\"Time\"\n",
    "        )\n",
    "        tracklets = [group for _, group in df.groupby(\"tracklet_id\")]\n",
    "        train_tracklets.extend(tracklets)\n",
    "    _, statistics = FeaturesScaler.scale_dataset(train_tracklets)\n",
    "    test_df = df = pd.read_csv(\n",
    "        os.path.join(DATA_PATH, test_scenario + \".csv\"), index_col=\"Time\"\n",
    "    )\n",
    "    test_tracklets = [group for _, group in test_df.groupby(\"tracklet_id\")]\n",
    "    test_ds = SimpleMagni(test_tracklets)\n",
    "    test_dl = DataLoader(test_ds, HYPERPARAMETERS[\"bs\"], shuffle=False)\n",
    "    return test_dl, statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_predictions = []\n",
    "for scenario in SCENARIOS:\n",
    "    checkpt_path = CHECKPOINTS_PATHS[scenario]\n",
    "    test_dl, statistics = get_test_dl_and_stats(scenario)\n",
    "    DATA_CONFIG.update(dict(training_data_stats=statistics))\n",
    "    model_pred = LightPointPredictor.load_from_checkpoint(\n",
    "        checkpt_path,\n",
    "        data_cfg=DATA_CONFIG,\n",
    "        network_cfg=NETWORK_CONFIG,\n",
    "        hyperparameters_cfg=HYPERPARAMETERS,\n",
    "        map_location={\"cuda:0\": \"cpu\"},\n",
    "    )\n",
    "    model_pred.eval()\n",
    "    scenario_predictions = []\n",
    "    for batch_idx, batch in enumerate(test_dl):\n",
    "        yhat = model_pred.predict_step(batch, batch_idx)\n",
    "        scenario_predictions.append(yhat[\"y_hat\"][0].numpy())\n",
    "    scenarios_predictions.append(np.concatenate(scenario_predictions, axis=0))\n",
    "scenarios_predictions = np.array(scenarios_predictions, dtype=object)\n",
    "np.save(\n",
    "    os.path.join(EXTRAS_PATH, \"simple_mlp_predictions.npy\"),\n",
    "    scenarios_predictions,\n",
    "    allow_pickle=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tragen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
